# Product Requirements Document (PRD)
# Simple AI Chat Client - Free Model Rate Limiter

## 1. Executive Summary

### 1.1 Project Overview
Build a **minimal Spring Boot service** that acts as a smart wrapper around free-tier AI chat models. The service automatically selects an available model based on rate limits, allowing you to experiment with AI chat applications without worrying about quota management.

### 1.2 Core Purpose
- **Single Goal**: Provide a simple chat API that automatically uses free AI models
- **No Complex Features**: Just rate limiting and model selection
- **For Experimentation**: Perfect for small tasks, prototyping, and learning

### 1.3 Use Case
```
You: "I want to build a chatbot"
Service: "Let me handle which free AI model to use based on limits"
You: Just call POST /chat with your message
Service: Returns AI response using the best available free model
```

---

## 2. Scope - What's INCLUDED âœ…

### 2.1 Core Features (Minimal Viable Product)
1. **Simple Chat API** - Single endpoint to send messages and get responses
2. **Rate Limit Tracking** - Track usage per model (per minute/day)
3. **Auto Model Selection** - Pick the best available free model
4. **Multiple Free Models** - Support 15+ free AI models (Gemini, Groq, etc.)
5. **Basic Monitoring** - Simple health check and usage stats

### 2.2 Supported Models
- **Google Gemini** (6 free models)
- **Groq/Meta-Llama** (8+ free models)
- **Others** (IBM Allam, Mistral, etc.)

---

## 3. Scope - What's EXCLUDED âŒ

### 3.1 NOT Included (Keep It Simple)
- âŒ Image/Document processing (text chat only)
- âŒ Admin UI or management console
- âŒ User authentication/authorization
- âŒ Multi-tenancy or per-user limits
- âŒ Conversation history/memory
- âŒ Streaming responses
- âŒ Custom model configuration via API
- âŒ Database persistence
- âŒ Advanced monitoring/alerting
- âŒ Load balancing across instances

---

## 4. Technical Architecture (Simplified)

### 4.1 Technology Stack
- **Framework**: Spring Boot 3.x
- **Language**: Java 17+
- **Cache**: Redis (for rate limiting only)
- **Build**: Maven
- **That's it!** No database, no Kafka, no complex infrastructure

### 4.2 Core Components (Only 5!)

```
1. AIModelRegistry     â†’ Stores model configs in memory
2. AIModelSelector     â†’ Picks best available model
3. AIUsageTracker      â†’ Tracks rate limits in Redis
4. ChatService         â†’ Calls AI APIs
5. ChatController      â†’ Single REST endpoint
```

---

## 5. API Design (Super Simple)

### 5.1 Main Endpoint - Chat

**POST /api/chat**
```json
Request:
{
  "message": "Explain quantum computing in simple terms"
}

Response:
{
  "reply": "Quantum computing is...",
  "model": "gemini-1.5-flash",
  "timestamp": "2026-01-31T10:30:00Z"
}
```

### 5.2 Optional Endpoints (Nice to Have)

**GET /api/models**
- List all available models and their limits

**GET /api/health**
- Check service health

**GET /api/stats**
- View current usage statistics

---

## 6. Data Models (Minimal)

### 6.1 ChatRequest
```java
{
  "message": "string"  // That's it!
}
```

### 6.2 ChatResponse
```java
{
  "reply": "string",
  "model": "string",
  "timestamp": "string"
}
```

### 6.3 AIModel (Internal)
```java
{
  "modelId": "string",
  "requestsPerMinute": "int",
  "requestsPerDay": "int",
  "isActive": "boolean"
}
```

---

## 7. Configuration (Environment Variables)

```bash
# Server
SERVER_PORT=8080

# Redis (for rate limiting)
REDIS_HOST=localhost
REDIS_PORT=6379

# API Keys (only what you need)
GEMINI_API_KEY=your-key-here
GROQ_API_KEY=your-key-here
```

---

## 8. Pre-configured Free Models

### 8.1 Best Free Models (Auto-configured)
```
1. gemini-1.5-flash        â†’ 15 req/min, 1500 req/day  â­ BEST
2. gemini-1.5-flash-8b     â†’ 15 req/min, 1500 req/day  â­ BEST
3. llama-3.1-8b-instant    â†’ 30 req/min, 14400 req/day â­ BEST
4. llama3-8b-8192          â†’ 30 req/min, 14400 req/day
5. gemini-1.5-pro          â†’ 2 req/min, 50 req/day
6. llama-3.3-70b-versatile â†’ 30 req/min, 1000 req/day
7. gemma2-9b-it            â†’ 30 req/min, 14400 req/day
8. deepseek-r1-distill     â†’ 30 req/min, 1000 req/day
```

**Total Daily Capacity**: ~50,000+ free requests per day!

---

## 9. Project Structure (Minimal)

```
simple-ai-chat-client/
â”œâ”€â”€ src/main/java/com/yourname/aichat/
â”‚   â”œâ”€â”€ controller/
â”‚   â”‚   â””â”€â”€ ChatController.java          â† Single REST controller
â”‚   â”œâ”€â”€ service/
â”‚   â”‚   â”œâ”€â”€ ChatService.java             â† Main chat logic
â”‚   â”‚   â””â”€â”€ CacheService.java            â† Redis wrapper
â”‚   â”œâ”€â”€ registry/
â”‚   â”‚   â””â”€â”€ AIModelRegistry.java         â† Model storage
â”‚   â”œâ”€â”€ selector/
â”‚   â”‚   â””â”€â”€ AIModelSelector.java         â† Model selection
â”‚   â”œâ”€â”€ tracker/
â”‚   â”‚   â””â”€â”€ AIUsageTracker.java          â† Rate limiting
â”‚   â”œâ”€â”€ provider/
â”‚   â”‚   â”œâ”€â”€ AIProvider.java              â† Interface
â”‚   â”‚   â”œâ”€â”€ GeminiProvider.java          â† Gemini API
â”‚   â”‚   â””â”€â”€ GroqProvider.java            â† Groq API
â”‚   â”œâ”€â”€ dto/
â”‚   â”‚   â”œâ”€â”€ ChatRequest.java
â”‚   â”‚   â”œâ”€â”€ ChatResponse.java
â”‚   â”‚   â””â”€â”€ AIModel.java
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ AIModelConfig.java           â† Model initialization
â”‚       â””â”€â”€ RedisConfig.java             â† Redis setup
â”œâ”€â”€ src/main/resources/
â”‚   â””â”€â”€ application.yaml
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md
```

**Total Files**: ~15 Java files (very manageable!)

---

## 10. Implementation Steps (Quick Start)

### Step 1: Create Spring Boot Project
```bash
# Use Spring Initializr
Dependencies: Web, Redis, Lombok
```

### Step 2: Copy Core Files from Reference
```bash
# Copy these 7 files from lumi-core-yaqeen-business:
1. AIModelRegistry.java
2. AIModelSelector.java
3. AIModelUsageTracker.java
4. GeminiProvider.java
5. GroqProvider.java
6. AIProvider.java (interface)
7. AIModel.java (DTO)
```

### Step 3: Create Simple ChatController
```java
@RestController
@RequestMapping("/api")
public class ChatController {
    
    @PostMapping("/chat")
    public ChatResponse chat(@RequestBody ChatRequest request) {
        // 1. Select best model
        // 2. Call AI API
        // 3. Return response
    }
}
```

### Step 4: Configure Models
```java
@PostConstruct
public void initModels() {
    // Register 8-10 best free models
    // Copy from AIModelConfig.java
}
```

### Step 5: Run!
```bash
mvn spring-boot:run
```

---

## 11. Usage Examples

### Example 1: Simple Chat
```bash
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What is AI?"}'
```

### Example 2: Check Available Models
```bash
curl http://localhost:8080/api/models
```

### Example 3: View Usage Stats
```bash
curl http://localhost:8080/api/stats
```

---

## 12. Dependencies (Minimal)

```xml
<dependencies>
    <!-- Spring Boot Web -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
    
    <!-- Redis for rate limiting -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-redis</artifactId>
    </dependency>
    
    <!-- Lombok (less boilerplate) -->
    <dependency>
        <groupId>org.projectlombok</groupId>
        <artifactId>lombok</artifactId>
    </dependency>
    
    <!-- That's it! -->
</dependencies>
```

---

## 13. How It Works (Simple Flow)

```
1. You send: POST /api/chat {"message": "Hello"}
2. Service checks: Which models have available quota?
3. Service selects: Best model (e.g., gemini-1.5-flash)
4. Service calls: Gemini API with your message
5. Service tracks: Increment usage counter in Redis
6. You receive: {"reply": "Hi there!", "model": "gemini-1.5-flash"}
```

**If model hits limit**: Automatically tries next available model!

---

## 14. Rate Limiting Logic (Simple)

```java
// For each model, track in Redis:
model:gemini-1.5-flash:requests_per_minute:1738320600000 = 5
model:gemini-1.5-flash:requests_per_day:1738320600000 = 120

// Before using model, check:
if (minuteCount < 15 && dayCount < 1500) {
    // Use this model
} else {
    // Try next model
}
```

---

## 15. Success Criteria (Keep It Simple)

### Launch Checklist
- âœ… Can send chat message and get response
- âœ… Automatically switches models when limits hit
- âœ… Tracks usage in Redis
- âœ… Works with 8+ free models
- âœ… Can run locally with Docker Redis
- âœ… Basic error handling
- âœ… README with examples

**That's it!** No complex requirements.

---

## 16. Timeline (Fast!)

- **Day 1**: Project setup, copy core files
- **Day 2**: Implement ChatController and ChatService
- **Day 3**: Testing and documentation
- **Day 4**: Polish and deploy

**Total Time**: 4 days (or 1-2 days if focused)

---

## 17. Future Enhancements (Optional)

### Phase 2 (If Needed)
- Conversation history (store last 10 messages)
- Streaming responses (SSE)
- Simple web UI for testing
- Docker Compose for easy deployment

### Phase 3 (Maybe)
- User API keys for rate limiting per user
- Prompt templates
- Cost tracking

**But for now**: Keep it simple!

---

## 18. Key Differences from Full PRD

| Feature | Full Gateway | Simple Chat Client |
|---------|-------------|-------------------|
| Purpose | Production service | Experimentation |
| Endpoints | 10+ APIs | 1-3 APIs |
| Features | Images, docs, admin | Text chat only |
| Auth | JWT/OAuth | None |
| Monitoring | Full observability | Basic health check |
| Deployment | K8s, multi-env | Local/Docker |
| Complexity | High | Low |
| Setup Time | 4 weeks | 4 days |

---

## 19. Quick Reference

### Start Redis
```bash
docker run -d -p 6379:6379 redis:alpine
```

### Run Service
```bash
mvn spring-boot:run
```

### Test Chat
```bash
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Tell me a joke"}'
```

### Check Health
```bash
curl http://localhost:8080/api/health
```

---

## 20. Summary

**What You Get**:
- âœ… Simple chat API
- âœ… 50,000+ free requests/day across multiple models
- âœ… Automatic rate limit management
- âœ… No quota worries
- âœ… Perfect for experiments

**What You Don't Get**:
- âŒ Complex features
- âŒ Production-grade infrastructure
- âŒ Advanced monitoring

**Perfect For**:
- ğŸ§ª AI experimentation
- ğŸ“š Learning AI APIs
- ğŸš€ Quick prototypes
- ğŸ’¡ Small projects

---

**Document Version**: 1.0 (Simplified)  
**Last Updated**: 2026-01-31  
**Status**: Ready for Quick Implementation  
**Estimated Setup Time**: 1-4 days

